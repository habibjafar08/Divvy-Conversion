{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **About the Company**\n",
    "\n",
    "---\n",
    "\n",
    "In 2016, Cyclistic launched a successful bike-share offering. Since then, the program has grown to a fleet of 5,824 bicycles that are geo tracked and locked into a network of 692 stations across Chicago. The bikes can be unlocked from one station and returned to any other station in the system anytime.\n",
    "\n",
    "<aside>\n",
    "ðŸ’¡ **Cyclistic:** A bike-share program that features more than 5,800 bicycles and 600 docking stations. Cyclistic sets itself apart by also offering reclining bikes, hand tricycles, and cargo bikes, making bike-share more inclusive to people with disabilities and riders who canâ€™t use a standard two-wheeled bike.\n",
    "\n",
    "</aside>\n",
    "\n",
    "## Business Context\n",
    "\n",
    "---\n",
    "\n",
    "Until now, Cyclisticâ€™s marketing strategy relied on building general awareness and appealing to broad consumer segments. One approach that helped make these things possible was the flexibility of its pricing plans: single-ride passes, full-day passes, and annual memberships. Customers who purchase single-ride or full-day passes are referred to as casual riders. Customers who purchase annual memberships are Cyclistic members.\n",
    "\n",
    "> **Cyclisticâ€™s finance analysts have concluded that annual members are much more profitable than casual riders**. Although the pricing flexibility helps Cyclistic attract more customers, Moreno, the director of marketing, believes that maximizing the number of annual members will be key to future growth. Rather than creating a marketing campaign that targets all-new customers, Moreno believes there is a very good chance to convert casual riders into members.\n",
    "> \n",
    "\n",
    "## Business Task\n",
    "\n",
    "---\n",
    "\n",
    "Moreno and her team are interested in analyzing the Cyclistic historical bike trip data to identify trends. Moreno has set a clear goal: ***Design marketing strategies aimed at converting casual riders into annual members***. In order to do that, however, the marketing analyst team needs to better understand:\n",
    "\n",
    "1. How annual members and casual riders differ?\n",
    "2. Why casual riders would buy a membership?\n",
    "3. How digital media could affect their marketing tactics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "---\n",
    "\n",
    "You are a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. Therefore, your team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, your team will design a new marketing strategy to convert casual riders into annual members. \n",
    "\n",
    "The key stakeholders in this project are:\n",
    "\n",
    "- **Lily Moreno:** The director of marketing and your manager. Moreno is responsible for the development of campaigns and initiatives to promote the bike-share program. These may include email, social media, and other channels.\n",
    "- **Cyclistic marketing analytics team:** A team of data analysts who are responsible for collecting, analyzing, and reporting data that helps guide Cyclistic marketing strategy.\n",
    "- **Cyclistic executive team:** The notoriously detail-oriented executive team will decide whether to approve the recommended marketing program.\n",
    "\n",
    "## Available Data\n",
    "\n",
    "---\n",
    "\n",
    "You will use Cyclisticâ€™s historical trip data to analyze and identify trends. This is public data that you can use to explore how different customer types are using Cyclistic bikes. The data has been made available by Motivate International Inc. under this **[license](https://ride.divvybikes.com/data-license-agreement),** you can download the data [**here**](https://divvy-tripdata.s3.amazonaws.com/index.html).\n",
    "\n",
    "| Column | Description |\n",
    "| --- | --- |\n",
    "| ride_id | The identification number for ride from start station to end station in given time. |\n",
    "| rideable_type | Cyclistic company bike type, there are 3 bike type classic bike, docked bike, and electric bike. |\n",
    "| started_at | Date and time when the ride begin. |\n",
    "| ended_at | Date and time when the ride end. |\n",
    "| day | Day name when the ride begin. |\n",
    "| start_station_name | The name of the station where the ride begin. |\n",
    "| start_station_id | The id of start station. |\n",
    "| end_station_name | The name of the station where the ride end. |\n",
    "| end_station_id | The id of end station. |\n",
    "| member_casual | The riders type in Cyclistic company. |\n",
    "| start_lat | Latitude of the start station. |\n",
    "| start_lng | Longitude of the start station. |\n",
    "| end_lat | Latitude of the end station. |\n",
    "| end_lng | Longitude of the end station. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "print(alt.__version__)\n",
    "\n",
    "alt.data_transformers.disable_max_rows()        #pastikan import ini juga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "Jan= pd.read_csv('202301-divvy-tripdata.csv', parse_dates=['started_at','ended_at'])\n",
    "Feb= pd.read_csv('202302-divvy-tripdata.csv', parse_dates=['started_at','ended_at'])\n",
    "Mar= pd.read_csv('202303-divvy-tripdata.csv', parse_dates=['started_at','ended_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Data\n",
    "df= pd.concat([Jan,Feb,Mar])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Information\n",
    "print(f'Jumlah baris dan kolom: {df.shape}')\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Name': df.columns.values,\n",
    "    'Type': df.dtypes.values,\n",
    "    'N/A (%)': df.isna().mean().values * 100,\n",
    "    'Unique': df.nunique().values,\n",
    "    'Sample': [df[col].unique() for col in df.columns]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terdapat ~14% Null Value pada nama stasiun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Duplicate Data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start station\n",
    "a= df[['start_station_name','start_lat','start_lng']]\n",
    "a.columns = ['station_name','lat','lng']\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop Station\n",
    "b= df[['end_station_name','end_lat','end_lng']]\n",
    "b.columns = ['station_name','lat','lng']\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Station gabungan\n",
    "station = pd.concat([a,b],axis=0).sort_values('station_name',ascending = False,na_position=\"last\")\n",
    "station.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicated data\n",
    "station.drop_duplicates(subset=['lat', 'lng'],keep='first', inplace=True, ignore_index=True)\n",
    "station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check duplicated data\n",
    "station.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station name Null\n",
    "station.station_name.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Create a sample DataFrame with NaN values\n",
    "station\n",
    "\n",
    "# Function to fill NaN values with random numbers\n",
    "def fillna_random(station_name):\n",
    "    nan_indices = station_name.isnull()  # Find indices of NaN values\n",
    "    num_nans = nan_indices.sum()   # Count NaN values\n",
    "    if num_nans > 0:\n",
    "        # Generate random numbers based on the non-NaN values in the column\n",
    "        random_values = random.sample(range(0,num_nans),num_nans)\n",
    "        # Replace NaN values with the generated random values\n",
    "        station_name[nan_indices] = random_values\n",
    "    return station_name\n",
    "\n",
    "# Apply the function to each column of the DataFrame\n",
    "station_filled = station.apply(fillna_random)\n",
    "\n",
    "\n",
    "station_filled.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Database station start\n",
    "station_start= station.copy()\n",
    "station_start['coorstart']= station_start.lat.astype(str)+','+station_start.lng.astype(str)\n",
    "station_start.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Database station stop\n",
    "station_stop= station.copy()\n",
    "station_stop['coorend']= station_stop.lat.astype(str)+','+station_stop.lng.astype(str)\n",
    "station_stop.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding column to database\n",
    "df['coorstart']= df.start_lat.astype(str)+','+df.start_lng.astype(str)\n",
    "df['coorend']= df.end_lat.astype(str)+','+df.end_lng.astype(str)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join with station start\n",
    "df2= pd.merge(df,station_start,how='left',on='coorstart')\n",
    "df2.rename(columns={'station_name':'start_station'}, inplace= True)\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join with station stop\n",
    "df3= pd.merge(df2,station_stop,how='left',on='coorend')\n",
    "df3.rename(columns={'station_name':'stop_station'}, inplace= True)\n",
    "df3.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting desired column\n",
    "df_clear= df3[['ride_id','rideable_type','started_at','ended_at','start_station','stop_station','member_casual']]\n",
    "df_clear.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clear\n",
    "df['rent_time']= (df.ended_at- df.started_at).astype(str)\n",
    "\n",
    "# Convert the 'Time' column to Timedelta\n",
    "df['rent_time'] = pd.to_timedelta(df['rent_time'])\n",
    "\n",
    "# Convert Timedelta to minutes\n",
    "df['Time_minutes'] = df['rent_time'].dt.total_seconds() / 60\n",
    "\n",
    "df['rent_time'] = pd.to_numeric(df['rent_time'])\n",
    "\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate day and hour\n",
    "df['day_of_week'] = df['started_at'].dt.day_name()\n",
    "df['month']= df['started_at'].dt.month_name()\n",
    "\n",
    "def hr_func(ts):\n",
    "    return ts.hour\n",
    "\n",
    "df['time_hour'] = df['started_at'].apply(hr_func)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "df.to_csv('data_clean.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= station.drop_duplicates(subset='station_name',keep='first', ignore_index=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "a.to_csv('station_database.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
